# Architecture consolidÃ©e ğŸ—ï¸âœ¨

Cette page prÃ©sente une vue dâ€™ensemble consolidÃ©e de lâ€™architecture de Huginn, les flux de donnÃ©es et les points dâ€™intÃ©gration clÃ©s. Elle est conÃ§ue pour Ãªtre gÃ©nÃ©rique et durable, indÃ©pendamment des implÃ©mentations ponctuelles. 

## Panorama des composants ğŸ§©
- ğŸŒ Frontend (Laravel) â€” Fournit lâ€™interface utilisateur et consomme lâ€™API backend.
- ğŸ§± Backend (Symfony) â€” Expose des endpoints, applique la logique mÃ©tier et orchestre les services.
- ğŸ§  Service LLM (Python) â€” Encapsule la gÃ©nÃ©ration et le streaming, expose des mÃ©triques Prometheus.
- ğŸ³ Docker Compose â€” Relie et configure les services pour le dev local.

## Diagramme (Mermaid) ğŸ—ºï¸
```mermaid
flowchart LR
  subgraph UI[UI / Frontend (Laravel)]
    A[Client Web]
  end
  subgraph API[API / Backend (Symfony)]
    B[ContrÃ´leurs
    + Cas d'usage]
  end
  subgraph LLM[Service LLM (Python)]
    C[HTTP generate/stream
    + CLI RNN]
    M[Metrics :9108 /metrics]
  end
  A -->|HTTP| B
  B -->|HTTP POST /generate/stream| C
  C -->|stream| B
  B -->|JSON| A
  M -.->|Prometheus scrape| Ext[(ObservabilitÃ©)]
```

## Flux de donnÃ©es ğŸ”„
1. Lâ€™utilisateur interagit avec le Frontend (Laravel).
2. Le Frontend appelle lâ€™API du Backend (Symfony).
3. Le Backend applique la logique mÃ©tier et dÃ©lÃ¨gue au Service LLM (Python) si nÃ©cessaire (gÃ©nÃ©ration/streaming).
4. Les rÃ©ponses remontent vers le Frontend. âœ…

## Points dâ€™intÃ©gration clÃ©s ğŸ”Œ
- URL LLM par dÃ©faut : `http://llm:8008/generate/stream` (configurable via `LLM_URL`).
- MÃ©triques : `http://localhost:9108/metrics` exposÃ© par le conteneur LLM.
- Volumes : `./ckpts -> /ckpts` (checkpoints), `./apps/python-llm -> /app/apps/python-llm`.

## RÃ©pertoires et fichiers utiles ğŸ“
- apps/laravel-front â€” contrÃ´leurs, routes, vues.
- apps/symfony-back â€” contrÃ´leurs, domaine, cas dâ€™usage.
  - src/Domain/Model/Prompt.php
  - src/Domain/Port/LLMGateway.php
  - src/Application/UseCase/GenerateStreamUseCase.php
  - src/Controller/LLMController.php
- apps/python-llm â€” composants LLM (llm_rnn, tokenizers, etc.).


# Backend ‚Äî Symfony üîô

Notes sp√©cifiques au backend Symfony. Pour des d√©tails d'impl√©mentation, voir le code sous apps/symfony-back.

## LLMGateway ‚Äî Client Python LLM
- Impl√©mentation: `apps/symfony-back/src/Infrastructure/LLM/PythonLLMClient.php`
- R√¥le: √©mettre une requ√™te HTTP POST vers l'endpoint du service LLM et consommer une r√©ponse en streaming.
- URL par d√©faut: `llm_url` (param√®tre Symfony) ou variable d'env `LLM_URL`; fallback: `http://llm:8008/generate/stream`.

Extrait important:
- Streaming via `HttpClientInterface` avec `buffer: false` puis it√©ration avec `$this->httpClient->stream($response)`.
- Les chunks sont relay√©s tels quels au consommateur (contr√¥leur/cas d'usage) pour un flux temps r√©el.

## Configuration
- Voir `compose.yaml` -> service `symfony-back`:
  - `LLM_URL` et `LLM_METRICS_URL` inject√©s via env.
- Param√©trage c√¥t√© Symfony (parameters, services) pour `llm_url`.

## Cas d'usage & contr√¥leurs
- Domaine: `src/Domain/Model/Prompt.php`, `src/Domain/Port/LLMGateway.php`
- Application: `src/Application/UseCase/GenerateStreamUseCase.php`
- Interface: `src/Controller/LLMController.php`

## D√©pannage
- 502/timeout en streaming: v√©rifier l'URL LLM, que le conteneur `llm` tourne, et aucun proxy n'interrompt la connexion.
- CORS/front: s'assurer que le contr√¥leur renvoie les en-t√™tes n√©cessaires selon le front.

Voir aussi:
- [LLM-Service-Python](LLM-Service-Python) ‚Äî endpoint attendu et m√©triques üß†
- [Architecture](Architecture) ‚Äî flux entre services üó∫Ô∏è